Naive Bayes Classifer (Week Base-line이 된다) 
이 이론의 접근 방식
"이게 왜 분류됬을까", "사람들은 왜 이렇게 분류했을까", "베이스라인 개념"
특징을 잡는다. 성질을 잡는다. 
(이미지, 다큐먼트-> 넘버) 바꾸는 과정에서 특징을 잡는다.  
ex) 남자와아이사진을 보고 이런 질문을 했다. 
is he married? 
힌트 ) 남자의 패션 ,함께 나온 아이
아이가 자식일 확률을 계산 ( 0.8 ) + 패션 ( 40대) ~~~+ 결혼했을 때 아이가 있을 확률( 0.0xxxx) 
# 이런식으로 feature들을 보고 분류를 한다. 
  
개지린다... 
![feature](img/feature.png)
픽셀 하나하나에다가 각 숫자의 가능성을 확률을 넣어서.. Cpt유추할 수 있다....
=> 즉 네이브 베이즈가 픽셀마다 독립적이다. 즉, 특징마다 모두 독립적이라는 말. 

그렇다면 픽셀에 그 확률을 어떻게 넣을 수 있을까? 

When would this p(y) table have non-uniform value?
0인 경우가 언제 있을까  ?  0 

p(y) = p( "free"|spam)  "spam메일에서 free라는 단어가 나왔냐. 

Empirically : use training data 
훈련한 데이터 중에 없는 학습이라면 확률이 0이 나온다. 
그래서 나온게  k+1/x+1 = 분자 분모에 값을 +1 혹은 다른 상수를 써서 더해준다. 
그래서 그 상수만큼 바뀐 값 만큼 다시 학습을 함. 

spam mail을 걸러내지 못한다면, feature를 늘려야한다 !!! 
